# Taiwan Localization Report

**Date**: 2025-11-10
**Goal**: Evaluate Taiwan-localized N-gram corpus for WebDaYi
**Status**: âš ï¸ **Completed with Important Findings**

---

## ğŸ“Š Summary

We implemented support for Taiwan-localized N-gram training using Rime's `terra_pinyin.dict.yaml` as suggested by the user. The implementation is **technically successful**, but the test results reveal **important limitations** that need to be addressed.

---

## âœ… Implementation Completed

### 1. **Terra Pinyin Parser** (NEW)
- **File**: `converter/build_ngram_lib.py`
- **Functions**:
  - `parse_terra_pinyin_dict()` - Parses Rime dict.yaml format
  - `parse_terra_pinyin_entry()` - Handles individual entries
- **Format Support**: `phrase\tpinyin` (no frequencies)
- **Strategy**: Assign uniform weight=1 to all entries

### 2. **Build Tool Enhancement**
- **File**: `converter/build_ngram.py`
- **New Parameter**: `--format [essay|terra_pinyin]`
- **Usage**:
  ```bash
  # Mainland corpus (default)
  python build_ngram.py --format essay --input essay.txt

  # Taiwan corpus
  python build_ngram.py --format terra_pinyin --input terra_pinyin.dict.yaml
  ```

### 3. **Taiwan N-gram Database**
- **File**: `mvp1/ngram_db_taiwan.json`
- **Size**: 5.4 MB (vs 15.7 MB mainland)
- **Source**: `terra_pinyin.dict.yaml` (99,327 entries)
- **Version**: 2.0 (with Laplace smoothing)

### 4. **Comparison Test Suite**
- **File**: `converter/test_taiwan_vs_mainland.js`
- **Tests**: Taiwan places, Taiwan-specific terms, common phrases
- **Result**: Comprehensive quality comparison

---

## ğŸ“ˆ Database Statistics Comparison

| Metric | Mainland (rime-essay) | Taiwan (terra_pinyin) | Winner |
|--------|----------------------|----------------------|---------|
| **Vocabulary Size** | 18,215 chars | 41,280 chars | Taiwan âœ“ |
| **Total Characters** | 717,006,728 | 208,294 | Mainland âœ“âœ“âœ“ |
| **Unique Bigrams** | 279,220 | 66,180 | Mainland âœ“âœ“ |
| **Database Size** | 15.7 MB | 5.4 MB | Taiwan âœ“ |
| **Data Type** | Corpus (with frequencies) | Dictionary (uniform) | Mainland âœ“âœ“ |

---

## ğŸ” Test Results: Taiwan vs Mainland

### Category 1: Taiwan Places

| Phrase | Description | Mainland Count | Taiwan Count | Winner |
|--------|-------------|----------------|--------------|---------|
| è‡ºç£ | Taiwan (traditional) | 50,967 âœ“ | 4 âœ“ | Mainland |
| å°åŒ— | Taipei | 0 âœ— | 0 âœ— | Tie |
| é«˜é›„ | Kaohsiung | 5,435 âœ“ | 0 âœ— | Mainland |
| æ–°ç«¹ | Hsinchu | 2,433 âœ“ | 0 âœ— | Mainland |

**Finding**: Mainland corpus has better coverage even for Taiwan places!

### Category 2: Taiwan-Specific Terms

| Phrase | Description | Mainland Count | Taiwan Count | Winner |
|--------|-------------|----------------|--------------|---------|
| ç¶²è·¯ | Internet (TW) | 10,667 âœ“ | 29 âœ“ | Mainland |
| è³‡è¨Š | Information (TW) | 13,417 âœ“ | 2 âœ“ | Mainland |
| è»Ÿé«” | Software (TW) | 4,022 âœ“ | 5 âœ“ | Mainland |
| æ·é‹ | MRT (TW) | 3,391 âœ“ | 1 âœ“ | Mainland |

**Finding**: Taiwan-specific vocabulary exists in both, but mainland has higher counts due to massive dataset size.

### Category 3: Common Phrases

| Phrase | Description | Mainland Count | Taiwan Count | Winner |
|--------|-------------|----------------|--------------|---------|
| å¤§å®¶ | Everyone | 365,429 âœ“ | 9 âœ“ | Mainland |
| æ™‚é–“ | Time | 390,539 âœ“ | 70 âœ“ | Mainland |
| å·¥ä½œ | Work | 431,648 âœ“ | 9 âœ“ | Mainland |
| æ•™è‚² | Education | 153,049 âœ“ | 119 âœ“ | Mainland |

**Finding**: Mainland corpus dominates in all categories due to 3,400x more data.

---

## ğŸš¨ Critical Findings

### Issue 1: Dictionary vs Corpus
- **Problem**: `terra_pinyin.dict.yaml` is a **dictionary** (word list), not a **corpus** (text with frequencies)
- **Impact**: All words have weight=1, no frequency information
- **Result**: Cannot learn real-world usage patterns

### Issue 2: Dataset Size Disparity
- **Mainland**: 717 million characters (real text data)
- **Taiwan**: 208 thousand characters (dictionary entries Ã— 1)
- **Ratio**: 3,400Ã— difference
- **Result**: Mainland corpus dominates even for Taiwan-specific terms

### Issue 3: Laplace Smoothing Impact
- **With small dataset**: Smoothing helps but cannot overcome lack of data
- **With large dataset**: Real frequencies dominate, better predictions
- **Conclusion**: More data > Better localization for this use case

---

## ğŸ’¡ Recommendations

### Option 1: Keep Mainland Corpus (RECOMMENDED)
**Pros:**
- âœ“ 717M characters of real text data
- âœ“ Better N-gram predictions for all phrases
- âœ“ Includes Taiwan vocabulary (ç¶²è·¯, è³‡è¨Š, etc.)
- âœ“ Already deployed and working well

**Cons:**
- âš  May use some mainland-specific terms (ç½‘ç»œ vs ç¶²è·¯)
- âš  Frequencies based on mainland usage patterns

**Recommendation**: **Use this for production**

### Option 2: Hybrid Approach
**Strategy**: Combine both corpora with weighted mixing
```python
# Pseudo-code
final_count = (mainland_count * 0.8) + (taiwan_count * 1000)
```

**Pros:**
- âœ“ Boost Taiwan-specific vocabulary
- âœ“ Keep mainland's large dataset
- âœ“ Customizable weights

**Cons:**
- âš  Complex implementation
- âš  Need careful tuning
- âš  May introduce artifacts

**Recommendation**: **Consider for future v11+ enhancement**

### Option 3: Find Better Taiwan Corpus
**Look for:**
- PTT (æ‰¹è¸¢è¸¢) text dumps (if available)
- Taiwan government documents
- Taiwan news article corpus
- Wikipedia Taiwan articles

**Pros:**
- âœ“ Real Taiwan usage patterns
- âœ“ Natural frequencies
- âœ“ Large dataset (if available)

**Cons:**
- âš  May be hard to find legal sources
- âš  Requires more data processing
- âš  Copyright/licensing issues

**Recommendation**: **Research for future versions**

### Option 4: User-Selectable Corpus (UI Enhancement)
**Strategy**: Let users choose in settings

**UI**:
```
âš™ï¸ èªæ–™åº«è¨­å®š (Corpus Settings)
  â—‹ å¤§é™¸èªæ–™åº« (Mainland) - æ¨è–¦ âœ“
     æ›´å¤§è³‡æ–™é›†ï¼Œæ›´æº–ç¢ºé æ¸¬
  â—‹ å°ç£èªæ–™åº« (Taiwan) - å¯¦é©—æ€§
     å°ç£è©å½™ï¼Œè³‡æ–™è¼ƒå°‘
```

**Recommendation**: **Nice-to-have for power users**

---

## ğŸ¯ Final Recommendation

**For MVP 1.0 v11 Production:**
1. âœ… **Keep mainland corpus (rime-essay)** as default
2. âœ… **Do NOT switch to Taiwan corpus** (data too small)
3. ğŸ“‹ **Document limitation**: N-gram based on mainland usage patterns
4. ğŸ“‹ **Future enhancement**: Consider hybrid or better Taiwan corpus

**Reasoning:**
- Mainland corpus has 3,400Ã— more data
- Even Taiwan-specific terms have better coverage in mainland corpus
- N-gram quality depends more on data volume than localization
- terra_pinyin is a dictionary, not a corpus (no frequency data)

---

## ğŸ“ Files Created/Modified

### New Files:
1. `converter/raw_data/terra_pinyin.dict.yaml` (1.8 MB) - Taiwan dictionary from Rime
2. `mvp1/ngram_db_taiwan.json` (5.4 MB) - Taiwan N-gram database
3. `converter/test_taiwan_vs_mainland.js` - Comparison test suite
4. `TAIWAN-LOCALIZATION.md` (this file) - Documentation

### Modified Files:
1. `converter/build_ngram_lib.py` - Added `parse_terra_pinyin_dict()` function
2. `converter/build_ngram.py` - Added `--format` parameter

---

## ğŸ”¬ Technical Details

### Parser Implementation

**Function**: `parse_terra_pinyin_dict(filepath: str)`
- Skips YAML header (until `...` marker)
- Parses `phrase\tpinyin` format
- Assigns uniform frequency=1 to all entries
- Returns `List[Tuple[str, int]]` compatible with existing pipeline

**Example**:
```python
>>> parse_terra_pinyin_entry("è‡ºç£\ttai2 wan1")
('è‡ºç£', 1)
```

### Build Command

**Taiwan corpus**:
```bash
python build_ngram.py \
  --format terra_pinyin \
  --input converter/raw_data/terra_pinyin.dict.yaml \
  --output mvp1/ngram_db_taiwan.json
```

**Output**:
```
Building N-gram database from terra_pinyin.dict.yaml (Taiwan localized)...
======================================================================
[1/5] Parsing terra_pinyin.dict.yaml...
  âœ“ Parsed 99,327 entries
[2/5] Counting unigrams...
  âœ“ Unique characters: 41,280
[3/5] Counting bigrams...
  âœ“ Unique bigrams: 66,180
[4/5] Calculating probabilities...
  âœ“ Smoothing: Laplace (Î±=0.1) - Solution B
[5/5] Writing ngram_db.json...
  âœ“ Output size: 5.3 MB
======================================================================
```

---

## ğŸ“ User Communication

**Message to User**:

> æ‚¨å¥½ï¼æˆ‘å·²å®Œæˆå°ç£åœ¨åœ°åŒ–èªæ–™åº«çš„æŠ€è¡“å¯¦ä½œã€‚
>
> **âœ… æŠ€è¡“å¯¦ä½œæˆåŠŸ**ï¼š
> - å·²æ”¯æ´ terra_pinyin.dict.yaml æ ¼å¼
> - ç”Ÿæˆäº†å°ç£ç‰ˆ ngram_db.json (5.4 MB)
> - å»ºç«‹äº†å°æ¯”æ¸¬è©¦å·¥å…·
>
> **âš ï¸ é‡è¦ç™¼ç¾**ï¼š
> æ¸¬è©¦çµæœé¡¯ç¤ºï¼Œrime-essay (å¤§é™¸èªæ–™åº«) åœ¨**æ‰€æœ‰é¡åˆ¥**éƒ½è¡¨ç¾æ›´å¥½ï¼ŒåŒ…æ‹¬ï¼š
> - å°ç£åœ°åï¼ˆè‡ºç£ã€é«˜é›„ã€æ–°ç«¹ï¼‰
> - å°ç£ç”¨èªï¼ˆç¶²è·¯ã€è³‡è¨Šã€æ·é‹ï¼‰
> - ä¸€èˆ¬è©å½™ï¼ˆå¤§å®¶ã€æ™‚é–“ã€å·¥ä½œï¼‰
>
> **åŸå› **ï¼š
> 1. terra_pinyin æ˜¯è©å…¸ï¼ˆword listï¼‰ï¼Œä¸æ˜¯èªæ–™åº«ï¼ˆcorpusï¼‰
> 2. è³‡æ–™é‡å·®è·ï¼š717M å­— vs 208K å­—ï¼ˆ3,400 å€ï¼‰
> 3. ç„¡é »ç‡è³‡è¨Šï¼ˆæ‰€æœ‰è©éƒ½æ˜¯ weight=1ï¼‰
>
> **å»ºè­°**ï¼š
> 1. **ä¿æŒä½¿ç”¨ rime-essayï¼ˆæ¨è–¦ï¼‰** - è³‡æ–™é‡å¤§ï¼Œé æ¸¬æ›´æº–ç¢º
> 2. æœªä¾†è€ƒæ…®æ··åˆå…©å€‹èªæ–™åº«ï¼ˆhybrid approachï¼‰
> 3. æˆ–å°‹æ‰¾æ›´å¥½çš„å°ç£èªæ–™åº«ï¼ˆå¦‚ PTTã€å°ç£æ–°èç­‰ï¼‰
>
> terra_pinyin ä½œç‚ºè©å…¸å¾ˆå„ªç§€ï¼Œä½†ç”¨æ–¼ N-gram è¨“ç·´æ™‚ï¼Œè³‡æ–™é‡ä¸è¶³æ˜¯è‡´å‘½å¼±é»ã€‚
>
> éœ€è¦æˆ‘æ¢ç´¢å…¶ä»–å°ç£èªæ–™åº«ä¾†æºå—ï¼Ÿ

---

## ğŸ”— Related Resources

- Rime terra_pinyin: https://github.com/rime/rime-terra-pinyin
- Rime essay: https://github.com/rime/rime-essay
- Wikipedia Chinese corpus: https://dumps.wikimedia.org/zhwiki/
- PTT corpus: (Need to research availability)

---

**Document Version**: 1.0
**Last Updated**: 2025-11-10
**Status**: Ready for user review and decision
