/**
 * TDD Tests for Laplace Smoothing (Solution B)
 *
 * Purpose: Verify that Laplace smoothing is correctly implemented in:
 * 1. build_ngram.py - Data generation with smoothing parameters
 * 2. viterbi_module.js - Algorithm using smoothing for probability calculation
 *
 * Laplace Smoothing Formula:
 * - P(char) = (count(char) + alpha) / (total_chars + alpha * vocab_size)
 * - P(c2|c1) = (count(c1,c2) + alpha) / (count(c1) + alpha * vocab_size)
 *
 * Where:
 * - alpha: Smoothing parameter (typically 0.1 or 1.0)
 * - total_chars: Sum of all character counts in corpus
 * - vocab_size: Number of unique characters
 *
 * Test Categories:
 * 1. Database Structure Tests (5 tests) - Verify ngram_db.json has smoothing params
 * 2. Unigram Smoothing Tests (4 tests) - Verify unigram probability calculation
 * 3. Bigram Smoothing Tests (5 tests) - Verify bigram probability calculation
 * 4. Edge Case Tests (4 tests) - Unseen events, zero counts
 * 5. Integration Tests (3 tests) - End-to-end with Viterbi
 *
 * Total: 21 tests
 */

const fs = require('fs');
const path = require('path');

// Load databases (files are in mvp1 root, two levels up from tests/node)
const rootDir = path.join(__dirname, '../..');
const ngramDbPath = path.join(rootDir, 'ngram_db.json');
let ngramDb;
try {
  ngramDb = JSON.parse(fs.readFileSync(ngramDbPath, 'utf-8'));
} catch (e) {
  ngramDb = null;  // Will be generated by Solution B
}

const dayiDbPath = path.join(rootDir, 'dayi_db.json');
const dayiDb = JSON.parse(fs.readFileSync(dayiDbPath, 'utf-8'));
const dayiMap = new Map(Object.entries(dayiDb));

// Load Viterbi module
const viterbiPath = path.join(rootDir, 'viterbi_module.js');
eval(fs.readFileSync(viterbiPath, 'utf-8'));

// Laplace smoothing helper functions (to be implemented in viterbi_module.js)
function getLaplaceUnigram(char, ngramDb) {
  const count = ngramDb.unigram_counts[char] || 0;
  const alpha = ngramDb.smoothing_alpha;
  const totalChars = ngramDb.total_chars;
  const vocabSize = ngramDb.vocab_size;

  return (count + alpha) / (totalChars + alpha * vocabSize);
}

function getLaplaceBigram(char1, char2, ngramDb) {
  const bigram = char1 + char2;
  const bigramCount = ngramDb.bigram_counts[bigram] || 0;
  const unigramCount = ngramDb.unigram_counts[char1] || 0;
  const alpha = ngramDb.smoothing_alpha;
  const vocabSize = ngramDb.vocab_size;

  return (bigramCount + alpha) / (unigramCount + alpha * vocabSize);
}

console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
console.log('â•‘   TDD Tests: Laplace Smoothing (Solution B)           â•‘');
console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

let passedTests = 0;
let totalTests = 0;

function test(name, fn) {
  totalTests++;
  try {
    fn();
    console.log(`âœ“ ${name}`);
    passedTests++;
  } catch (error) {
    console.log(`âœ— ${name}`);
    console.log(`  Error: ${error.message}`);
  }
}

console.log('=== Category 1: Database Structure Tests (5 tests) ===\n');

test('Test 1.1: ngram_db.json should have smoothing_alpha', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found (need to regenerate)');
  if (typeof ngramDb.smoothing_alpha !== 'number') {
    throw new Error('smoothing_alpha missing or not a number');
  }
  if (ngramDb.smoothing_alpha <= 0) {
    throw new Error('smoothing_alpha must be positive');
  }
});

test('Test 1.2: ngram_db.json should have total_chars', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found (need to regenerate)');
  if (typeof ngramDb.total_chars !== 'number') {
    throw new Error('total_chars missing or not a number');
  }
  if (ngramDb.total_chars <= 0) {
    throw new Error('total_chars must be positive');
  }
});

test('Test 1.3: ngram_db.json should have vocab_size', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found (need to regenerate)');
  if (typeof ngramDb.vocab_size !== 'number') {
    throw new Error('vocab_size missing or not a number');
  }
  if (ngramDb.vocab_size <= 0) {
    throw new Error('vocab_size must be positive');
  }
});

test('Test 1.4: ngram_db.json should have unigram_counts', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found (need to regenerate)');
  if (typeof ngramDb.unigram_counts !== 'object') {
    throw new Error('unigram_counts missing or not an object');
  }
  if (Object.keys(ngramDb.unigram_counts).length === 0) {
    throw new Error('unigram_counts is empty');
  }
});

test('Test 1.5: ngram_db.json should have bigram_counts', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found (need to regenerate)');
  if (typeof ngramDb.bigram_counts !== 'object') {
    throw new Error('bigram_counts missing or not an object');
  }
  if (Object.keys(ngramDb.bigram_counts).length === 0) {
    throw new Error('bigram_counts is empty');
  }
});

console.log('\n=== Category 2: Unigram Smoothing Tests (4 tests) ===\n');

test('Test 2.1: Laplace smoothing for seen unigram', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Find a character we know exists
  const char = Object.keys(ngramDb.unigram_counts)[0];
  const prob = getLaplaceUnigram(char, ngramDb);

  if (prob <= 0) throw new Error('Probability must be positive');
  if (prob > 1) throw new Error('Probability must be <= 1');
});

test('Test 2.2: Laplace smoothing for unseen unigram', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Use a rare character unlikely to be in corpus
  const unseenChar = 'ðŸ¦„';  // Emoji unlikely in Chinese corpus
  const prob = getLaplaceUnigram(unseenChar, ngramDb);

  if (prob <= 0) throw new Error('Unseen events should have non-zero probability');
  if (prob > 1) throw new Error('Probability must be <= 1');

  // Should be very small but not zero
  const expectedSmallProb = ngramDb.smoothing_alpha /
                           (ngramDb.total_chars + ngramDb.smoothing_alpha * ngramDb.vocab_size);
  if (Math.abs(prob - expectedSmallProb) > 0.0001) {
    throw new Error(`Expected ${expectedSmallProb}, got ${prob}`);
  }
});

test('Test 2.3: Common characters should have higher probability', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Find most common and least common characters
  const counts = ngramDb.unigram_counts;
  const chars = Object.keys(counts);
  const sortedChars = chars.sort((a, b) => counts[b] - counts[a]);

  const mostCommon = sortedChars[0];
  const leastCommon = sortedChars[sortedChars.length - 1];

  const probMost = getLaplaceUnigram(mostCommon, ngramDb);
  const probLeast = getLaplaceUnigram(leastCommon, ngramDb);

  if (probMost <= probLeast) {
    throw new Error('Most common should have higher probability than least common');
  }
});

test('Test 2.4: All unigram probabilities should sum to ~1.0', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // This is not strictly true with Laplace smoothing (can be slightly > 1),
  // but should be close
  const chars = Object.keys(ngramDb.unigram_counts);
  let sum = 0;
  for (const char of chars) {
    sum += getLaplaceUnigram(char, ngramDb);
  }

  // Allow 10% margin due to unseen events
  if (sum < 0.9 || sum > 1.5) {
    throw new Error(`Sum should be ~1.0, got ${sum}`);
  }
});

console.log('\n=== Category 3: Bigram Smoothing Tests (5 tests) ===\n');

test('Test 3.1: Laplace smoothing for seen bigram', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Find a bigram we know exists
  const bigram = Object.keys(ngramDb.bigram_counts)[0];
  const char1 = bigram[0];
  const char2 = bigram[1];

  const prob = getLaplaceBigram(char1, char2, ngramDb);

  if (prob <= 0) throw new Error('Probability must be positive');
  if (prob > 1) throw new Error('Probability must be <= 1');
});

test('Test 3.2: Laplace smoothing for unseen bigram', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Create an unseen bigram
  const char1 = Object.keys(ngramDb.unigram_counts)[0];
  const char2 = 'ðŸ¦„';  // Unlikely in corpus

  const prob = getLaplaceBigram(char1, char2, ngramDb);

  if (prob <= 0) throw new Error('Unseen bigrams should have non-zero probability');
  if (prob > 1) throw new Error('Probability must be <= 1');
});

test('Test 3.3: Common bigrams should have higher probability', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Find most and least common bigrams
  const counts = ngramDb.bigram_counts;
  const bigrams = Object.keys(counts);
  const sortedBigrams = bigrams.sort((a, b) => counts[b] - counts[a]);

  const most = sortedBigrams[0];
  const least = sortedBigrams[sortedBigrams.length - 1];

  const probMost = getLaplaceBigram(most[0], most[1], ngramDb);
  const probLeast = getLaplaceBigram(least[0], least[1], ngramDb);

  if (probMost <= probLeast) {
    throw new Error('Most common bigram should have higher probability');
  }
});

test('Test 3.4: Bigram smoothing better than fixed 1e-10', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // For an unseen bigram
  const char1 = Object.keys(ngramDb.unigram_counts)[0];
  const char2 = 'ðŸ¦„';

  const laplaceProb = getLaplaceBigram(char1, char2, ngramDb);
  const oldFallback = 1e-10;

  // Laplace should give MUCH better probability than 1e-10
  if (laplaceProb <= oldFallback) {
    throw new Error(`Laplace (${laplaceProb}) should be > old fallback (${oldFallback})`);
  }

  // Should be at least 1000x better
  if (laplaceProb / oldFallback < 1000) {
    throw new Error(`Improvement not significant enough`);
  }
});

test('Test 3.5: Conditional probabilities should sum to ~1.0', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // For a given first character, P(c2|c1) should sum to ~1.0 over all c2
  const char1 = Object.keys(ngramDb.unigram_counts)[0];
  const allChars = Object.keys(ngramDb.unigram_counts);

  // Sample a subset (testing all would be too slow)
  const sample = allChars.slice(0, 100);
  let sum = 0;
  for (const char2 of sample) {
    sum += getLaplaceBigram(char1, char2, ngramDb);
  }

  // With smoothing and sampling, this won't be exactly 1.0
  // but should be reasonable
  if (sum < 0.01) {  // At least some probability distributed
    throw new Error(`Conditional probabilities too small: ${sum}`);
  }
});

console.log('\n=== Category 4: Edge Case Tests (4 tests) ===\n');

test('Test 4.1: Handle zero unigram count', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  const unseenChar = 'ðŸ¦„';
  const prob = getLaplaceUnigram(unseenChar, ngramDb);

  // With Laplace smoothing, even zero count should give non-zero prob
  const expected = ngramDb.smoothing_alpha /
                   (ngramDb.total_chars + ngramDb.smoothing_alpha * ngramDb.vocab_size);

  if (Math.abs(prob - expected) > 0.0001) {
    throw new Error(`Expected ${expected}, got ${prob}`);
  }
});

test('Test 4.2: Handle zero bigram count', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  const char1 = Object.keys(ngramDb.unigram_counts)[0];
  const char2 = 'ðŸ¦„';

  const prob = getLaplaceBigram(char1, char2, ngramDb);

  // Should be non-zero even for unseen bigram
  if (prob <= 0) {
    throw new Error('Zero bigram count should still have non-zero probability');
  }
});

test('Test 4.3: Different alpha values change probabilities', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  const char = Object.keys(ngramDb.unigram_counts)[0];

  // Simulate different alpha
  const alpha1 = 0.1;
  const alpha2 = 1.0;

  const count = ngramDb.unigram_counts[char];
  const total = ngramDb.total_chars;
  const vocab = ngramDb.vocab_size;

  const prob1 = (count + alpha1) / (total + alpha1 * vocab);
  const prob2 = (count + alpha2) / (total + alpha2 * vocab);

  // Different alphas should give different results
  if (prob1 === prob2) {
    throw new Error('Different alpha values should produce different probabilities');
  }
});

test('Test 4.4: Very small alpha approaches no smoothing', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  const char = Object.keys(ngramDb.unigram_counts)[0];
  const count = ngramDb.unigram_counts[char];
  const total = ngramDb.total_chars;
  const vocab = ngramDb.vocab_size;

  // With very small alpha
  const alpha = 0.00001;
  const probSmooth = (count + alpha) / (total + alpha * vocab);
  const probRaw = count / total;

  // Should be very close to raw probability
  if (Math.abs(probSmooth - probRaw) > 0.001) {
    throw new Error('Very small alpha should approximate raw probability');
  }
});

console.log('\n=== Category 5: Integration Tests (3 tests) ===\n');

test('Test 5.1: Viterbi uses Laplace smoothing for predictions', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  // Test a simple prediction
  const codes = ['v', 'd/'];  // å¤§æ˜“

  try {
    const result = viterbi(codes, dayiMap, ngramDb);

    if (!result || !result.sentence) {
      throw new Error('Viterbi should return a result');
    }

    // Score should be reasonable (not extreme negative due to 1e-10)
    if (result.score < -50) {
      throw new Error(`Score too low: ${result.score} (indicates poor smoothing)`);
    }
  } catch (e) {
    throw new Error(`Viterbi failed: ${e.message}`);
  }
});

test('Test 5.2: Predictions better with Laplace than with 1e-10', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  const codes = ['v', 'd/'];

  try {
    const result = viterbi(codes, dayiMap, ngramDb);

    // With Laplace smoothing, scores should be less negative
    // (less penalty for unseen events)
    if (result.score < -30) {
      console.log(`  Note: Score is ${result.score}, may still need tuning`);
    }
  } catch (e) {
    throw new Error(`Viterbi failed: ${e.message}`);
  }
});

test('Test 5.3: Longer sequences work with Laplace smoothing', () => {
  if (!ngramDb) throw new Error('ngram_db.json not found');

  const codes = ['v5', 'sf', 'v', 'd/'];  // æˆ‘åœ¨å¤§æ˜“

  try {
    const result = viterbi(codes, dayiMap, ngramDb);

    if (!result || !result.sentence || result.sentence.length !== 4) {
      throw new Error('Should predict 4-character sentence');
    }

    // Score should be reasonable even for longer sequence
    if (result.score < -100) {
      throw new Error(`Score too low for 4-char sequence: ${result.score}`);
    }
  } catch (e) {
    throw new Error(`Viterbi failed on longer sequence: ${e.message}`);
  }
});

// Summary
console.log('\n=== Test Summary ===\n');
console.log(`Total: ${passedTests}/${totalTests} tests passing`);

if (passedTests === totalTests) {
  console.log('\nâœ“ All tests PASSED! Laplace smoothing implemented correctly! ðŸŽ‰\n');
} else {
  console.log(`\nâœ— ${totalTests - passedTests} test(s) FAILED. Review implementation.\n`);
  process.exit(1);
}
